"""
Application Streamlit pour GraphRAG avec Ollama
Interface pour uploader des documents et interroger le RAG
"""

import streamlit as st
import asyncio
import os
from pathlib import Path
from datetime import datetime

from main import initialize_rag
from lightrag import QueryParam
from document_processor import DocumentProcessor

# Configuration de la page
st.set_page_config(
    page_title="Caf√©IA - graphRAG avec Ollama",
    page_icon="‚òï",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Styles CSS personnalis√©s
st.markdown("""
    <style>
    .main-header {
        font-size: 5rem !important;
        font-weight: bold !important;
        text-align: center !important;
        color: #1f77b4 !important;
        margin-bottom: 0.5rem !important;
        margin-top: 1rem !important;
        line-height: 1.2 !important;
    }
    .sub-header {
        font-size: 1.2rem;
        text-align: center;
        color: #666;
        margin-bottom: 2rem;
    }
    .upload-section {
        background-color: #f0f2f6;
        padding: 20px;
        border-radius: 10px;
        margin-bottom: 20px;
    }
    .query-section {
        background-color: #e8f4f8;
        padding: 20px;
        border-radius: 10px;
        margin-bottom: 20px;
    }
    .stAlert {
        margin-top: 10px;
    }
    </style>
""", unsafe_allow_html=True)

# Initialisation de l'√©tat de session
if 'rag_initialized' not in st.session_state:
    st.session_state.rag_initialized = False
if 'rag_instance' not in st.session_state:
    st.session_state.rag_instance = None
if 'uploaded_files_count' not in st.session_state:
    st.session_state.uploaded_files_count = 0
if 'uploaded_files_list' not in st.session_state:
    st.session_state.uploaded_files_list = []
if 'query_history' not in st.session_state:
    st.session_state.query_history = []


async def init_rag():
    """Initialise l'instance RAG de mani√®re asynchrone."""
    # Ne pas mettre en cache pour √©viter les probl√®mes d'event loop
    rag = await initialize_rag()
    return rag


async def insert_document_to_rag(text: str, filename: str):
    """Ins√®re un document dans le RAG."""
    rag = await initialize_rag()
    await rag.ainsert(text)


async def query_rag(question: str, mode: str):
    """Interroge le RAG avec la question et le mode sp√©cifi√©s."""
    rag = await initialize_rag()
    result = await rag.aquery(
        question,
        param=QueryParam(mode=mode)
    )
    return result


def main():
    # En-t√™te avec logos
    col1, col2, col3 = st.columns([1, 3, 1])

    with col1:
        st.image("IMG/upvd_logo.png", width=150)

    with col2:
        st.markdown('<p class="main-header">‚òï Caf√©IA - GraphRAG</p>', unsafe_allow_html=True)
        st.markdown('<p class="sub-header">Interface de gestion documentaire et interrogation LLM avec Ollama</p>', unsafe_allow_html=True)

    with col3:
        st.image("IMG/mensaflow_logo.jpg", width=150)

    # V√©rifier qu'Ollama est disponible (test au d√©marrage)
    if not st.session_state.get('ollama_checked', False):
        try:
            import requests
            response = requests.get("http://localhost:11434/api/tags", timeout=2)
            if response.status_code == 200:
                st.session_state.ollama_checked = True
            else:
                st.error("Ollama ne r√©pond pas correctement")
                st.info("Assurez-vous qu'Ollama est lanc√© avec: ollama serve")
                st.stop()
        except Exception as e:
            st.error("Impossible de se connecter √† Ollama")
            st.info("Assurez-vous qu'Ollama est lanc√© et que les mod√®les sont disponibles (qwen2.5:14b et nomic-embed-text)")
            st.stop()

    # Barre lat√©rale - Informations et configuration
    with st.sidebar:
        st.header("üìä Informations")
        st.info(f"""
        **Mod√®le LLM:** qwen2.5:14b
        **Mod√®le Embedding:** nomic-embed-text
        **Documents index√©s:** {st.session_state.uploaded_files_count}
        """)

        st.header("‚öôÔ∏è Configuration")
        st.caption("Les param√®tres sont d√©finis dans main.py")

        st.header("üìö Guide d'utilisation")
        with st.expander("Comment utiliser cette application ?"):
            st.markdown("""
            1. **Uploader des documents** dans la section appropri√©e
            2. Les documents seront automatiquement index√©s dans le RAG
            3. **Poser vos questions** dans la section de requ√™te
            4. Choisir le **mode de recherche** adapt√© √† votre besoin
            """)

        with st.expander("Modes de recherche"):
            st.markdown("""
            - **Naive:** RAG classique, recherche simple
            - **Local:** Entit√©s et relations proches (1 hop)
            - **Global:** Patterns globaux du knowledge graph
            - **Hybrid:** Combinaison local + global (recommand√©)
            """)

    # Onglets principaux
    tab1, tab2, tab3 = st.tabs(["üì§ Upload Documents", "üí¨ Interroger le RAG", "üìú Historique"])

    # --- TAB 1: Upload de documents ---
    with tab1:
        st.markdown('<div class="upload-section">', unsafe_allow_html=True)
        st.header("üì§ Importer des documents")

        uploaded_files = st.file_uploader(
            "Glissez-d√©posez vos documents ou cliquez pour parcourir",
            type=['pdf', 'docx', 'xlsx', 'txt'],
            accept_multiple_files=True,
            help="Formats support√©s : PDF, DOCX, XLSX, TXT"
        )

        if uploaded_files:
            st.subheader(f"üìÅ {len(uploaded_files)} fichier(s) s√©lectionn√©(s)")

            if st.button("üöÄ Indexer les documents", type="primary", use_container_width=True):
                progress_bar = st.progress(0)
                status_text = st.empty()

                for idx, uploaded_file in enumerate(uploaded_files):
                    try:
                        status_text.text(f"Traitement de {uploaded_file.name}...")

                        # Extraire le texte selon le format
                        file_extension = Path(uploaded_file.name).suffix
                        text = DocumentProcessor.process_uploaded_file(uploaded_file, file_extension)

                        if text and text.strip():
                            # Ins√©rer dans le RAG
                            asyncio.run(insert_document_to_rag(text, uploaded_file.name))
                            st.success(f"‚úÖ {uploaded_file.name} index√© avec succ√®s!")
                            st.session_state.uploaded_files_count += 1
                            # Ajouter √† la liste des fichiers upload√©s
                            if uploaded_file.name not in st.session_state.uploaded_files_list:
                                st.session_state.uploaded_files_list.append({
                                    'name': uploaded_file.name,
                                    'size': uploaded_file.size,
                                    'type': file_extension,
                                    'timestamp': datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                                })
                        else:
                            st.warning(f"‚ö†Ô∏è {uploaded_file.name} ne contient pas de texte exploitable")

                    except Exception as e:
                        st.error(f"‚ùå Erreur avec {uploaded_file.name}: {str(e)}")

                    # Mise √† jour de la barre de progression
                    progress_bar.progress((idx + 1) / len(uploaded_files))

                status_text.text("‚ú® Indexation termin√©e!")
                st.balloons()

        st.markdown('</div>', unsafe_allow_html=True)

        # Afficher les formats support√©s
        with st.expander("‚ÑπÔ∏è Formats support√©s"):
            st.markdown("""
            - **PDF** (.pdf) : Documents Adobe PDF
            - **Word** (.docx) : Documents Microsoft Word
            - **Excel** (.xlsx) : Feuilles de calcul Excel
            - **Texte** (.txt) : Fichiers texte brut
            """)

    # --- TAB 2: Interrogation du RAG ---
    with tab2:
        st.markdown('<div class="query-section">', unsafe_allow_html=True)
        st.header("üí¨ Poser une question au RAG")

        # Zone de saisie de la question
        question = st.text_area(
            "Votre question :",
            height=100,
            placeholder="Ex: Quel technicien certifi√© est disponible en Occitanie ?",
            help="Posez une question sur les documents que vous avez index√©s"
        )

        col1, col2 = st.columns([3, 1])

        with col1:
            query_mode = st.selectbox(
                "Mode de recherche :",
                options=['hybrid', 'naive', 'local', 'global'],
                index=0,
                help="Hybrid est recommand√© pour des questions complexes"
            )

        with col2:
            st.write("")  # Spacer
            st.write("")  # Spacer
            query_button = st.button("üîç Rechercher", type="primary", use_container_width=True)

        if query_button and question.strip():
            try:
                with st.spinner(f"Recherche en mode {query_mode}..."):
                    result = asyncio.run(query_rag(question, query_mode))

                    # Afficher le r√©sultat
                    st.subheader("üìù R√©ponse :")
                    st.markdown(result)

                    # Section Sources du Retrieval
                    with st.expander("üìö Sources utilis√©es pour cette r√©ponse", expanded=False):
                        st.markdown(f"""
                        **Mode de recherche :** `{query_mode}`

                        **Type de retrieval :**
                        """)

                        if query_mode == "naive":
                            st.info("üîç **RAG classique** - Recherche par similarit√© vectorielle dans les chunks de documents")
                        elif query_mode == "local":
                            st.info("üîó **Graph local** - Entit√©s et relations proches (1 hop) dans le knowledge graph")
                        elif query_mode == "global":
                            st.info("üåê **Graph global** - Patterns et structures globales du knowledge graph")
                        elif query_mode == "hybrid":
                            st.info("üéØ **Hybrid (Recommand√©)** - Combinaison de recherche locale ET globale pour des r√©ponses multi-hop complexes")

                        st.markdown("---")
                        st.markdown("### üìÑ Documents index√©s dans le knowledge graph")

                        if st.session_state.uploaded_files_list:
                            for idx, file_info in enumerate(st.session_state.uploaded_files_list, 1):
                                st.markdown(f"""
                                **{idx}. {file_info['name']}**
                                - üìÅ Type: `{file_info['type']}`
                                - üìä Taille: {file_info['size'] / 1024:.2f} KB
                                - üïê Index√© le: {file_info['timestamp']}
                                """)
                        else:
                            st.warning("Aucun document index√© pour le moment")

                        st.markdown("---")
                        st.markdown(f"""
                        **Total de documents :** {st.session_state.uploaded_files_count}

                        **R√©pertoire de stockage :** `./storage/`

                        üí° *Les sources proviennent du knowledge graph construit √† partir de ces documents.*
                        """)

                        # Lien vers le dossier storage pour inspection manuelle
                        if os.path.exists("./storage"):
                            st.caption("Les fichiers du knowledge graph sont disponibles dans le dossier `storage/`")

                    # Ajouter √† l'historique
                    st.session_state.query_history.append({
                        'timestamp': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                        'question': question,
                        'mode': query_mode,
                        'answer': result
                    })

                    st.success("‚úÖ R√©ponse g√©n√©r√©e avec succ√®s!")

            except Exception as e:
                st.error(f"‚ùå Erreur lors de la requ√™te : {str(e)}")

        elif query_button and not question.strip():
            st.warning("‚ö†Ô∏è Veuillez saisir une question avant de lancer la recherche.")

        st.markdown('</div>', unsafe_allow_html=True)

    # --- TAB 3: Historique ---
    with tab3:
        st.header("üìú Historique des requ√™tes")

        if st.session_state.query_history:
            # Bouton pour effacer l'historique
            if st.button("üóëÔ∏è Effacer l'historique"):
                st.session_state.query_history = []
                st.rerun()

            # Afficher l'historique en ordre inverse (plus r√©cent en premier)
            for idx, query in enumerate(reversed(st.session_state.query_history)):
                with st.expander(f"üïê {query['timestamp']} - Mode: {query['mode']}"):
                    st.markdown(f"**Question:** {query['question']}")
                    st.markdown("---")
                    st.markdown(f"**R√©ponse:**")
                    st.markdown(query['answer'])
        else:
            st.info("Aucune requ√™te dans l'historique. Commencez par poser une question dans l'onglet 'Interroger le RAG'.")

    # Footer
    st.markdown("---")
    st.markdown(
        '<p style="text-align: center; color: #888;">‚òï Caf√©IA - Powered by GraphRAG & Ollama</p>',
        unsafe_allow_html=True
    )


if __name__ == "__main__":
    main()
